X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
rho
Nsims = 10
popNum = 2
subNum = 5
p = 25
n = 30
rho = .2
rm(list=ls())
gc()
rm(list=ls())
gc()
library(MASS)
library(igraph)
library(mclust)
library(JGL) # might be better idea to use my own implementation for FGL
source('/media/1401-1FFE/Documents/Model Based Clustering/Code/PenalisedVanillaMoG_02.R')
source('/media/1401-1FFE/Documents/Model Based Clustering/Code/NetworkSim.R')
source('/media/1401-1FFE/Documents/Model Based Clustering/Simulations/BreakJGL/Helper_01.R')
source('/media/1401-1FFE/Documents/Model Based Clustering/Code/FGL/FGL.R')
source('/media/1401-1FFE/Documents/Model Based Clustering/Simulations/BreakJGL/SimilarNetworkGeneration_01.R')
## ---- SIMULATION 1 ---- ##
Nsims = 10
popNum = 2
subNum = 5
p = 25
n = 30
rho = .2
ResultsMoG = data.frame(matrix(0, ncol=9, nrow=Nsims))
names(ResultsMoG) = c("SimID", "TP", "FP", "Sens", "Spec", "FDR", "TPR", "Pres", "Recall")
ResultsFGL= data.frame(matrix(0, ncol=9, nrow=Nsims))
names(ResultsFGL) = c("SimID", "TP", "FP", "Sens", "Spec", "FDR", "TPR", "Pres", "Recall")
ResultsGGL= data.frame(matrix(0, ncol=9, nrow=Nsims))
names(ResultsGGL) = c("SimID", "TP", "FP", "Sens", "Spec", "FDR", "TPR", "Pres", "Recall")
ResultsGL= data.frame(matrix(0, ncol=9, nrow=Nsims))
names(ResultsGL) = c("SimID", "TP", "FP", "Sens", "Spec", "FDR", "TPR", "Pres", "Recall")
i=1
set.seed(i)
randomNetworks = Gen2SharedNetworks(p = p, rho = rho, sparsity = .4)
P = vector("list", 2)
P[[1]] = randomNetworks$y
P[[2]] = randomNetworks$y2
### now simulate data:
D = NULL
for (j in 1:popNum){
DpopJ = vector("list", subNum)
for (k in 1:subNum){
DpopJ[[k]] = mvrnorm(n = n, mu = rep(0, p), P[[j]])
}
D = append(D, DpopJ)
}
D = lapply(D, scale)
### now run various models & store results:
# MoG model:
lamMOG= regChoice(D=D, lambda = c(0.005, 0.01, 0.025, 0.05, 0.1), K=2, SampleNo = 10, Ptype="Classic")
lamMOG
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X$iter
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
X$iter
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
X$iter
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
lamMOG= regChoice(D=D, lambda = c(0.005, 0.01, 0.025, 0.05), K=2, SampleNo = 10, Ptype="Classic")
lamMOG
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
X$iter
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
X$iter
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X$iter
lamMOG = lamMOG/2
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
X$iter
lamMOG= regChoice(D=D, lambda = c(0.05, .1, .15, .2), K=2, SampleNo = 10, Ptype="Classic")
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
X$iter
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
lamMOG = .15
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
ii = which(P[[1]][upper.tri(P[[1]])]!=0)
ii2 = which(P[[2]][upper.tri(P[[1]])]!=0)
sum(ii %in% ii2)
length(ii)
rho = 0
set.seed(i)
randomNetworks = Gen2SharedNetworks(p = p, rho = rho, sparsity = .4)
P = vector("list", 2)
P[[1]] = randomNetworks$y
P[[2]] = randomNetworks$y2
### now simulate data:
D = NULL
for (j in 1:popNum){
DpopJ = vector("list", subNum)
for (k in 1:subNum){
DpopJ[[k]] = mvrnorm(n = n, mu = rep(0, p), P[[j]])
}
D = append(D, DpopJ)
}
D = lapply(D, scale)
### now run various models & store results:
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
X$iter
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
p = 10
set.seed(i)
randomNetworks = Gen2SharedNetworks(p = p, rho = rho, sparsity = .4)
P = vector("list", 2)
P[[1]] = randomNetworks$y
P[[2]] = randomNetworks$y2
### now simulate data:
D = NULL
for (j in 1:popNum){
DpopJ = vector("list", subNum)
for (k in 1:subNum){
DpopJ[[k]] = mvrnorm(n = n, mu = rep(0, p), P[[j]])
}
D = append(D, DpopJ)
}
D = lapply(D, scale)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
choose(10,2)
choose(20,2)
choose(20,2)*(2/3)
Nsims = 10
popNum = 2
subNum = 5
p = 20
n = 50
set.seed(i)
randomNetworks = Gen2SharedNetworks(p = p, rho = rho, sparsity = .4)
P = vector("list", 2)
P[[1]] = randomNetworks$y
P[[2]] = randomNetworks$y2
### now simulate data:
D = NULL
for (j in 1:popNum){
DpopJ = vector("list", subNum)
for (k in 1:subNum){
DpopJ[[k]] = mvrnorm(n = n, mu = rep(0, p), P[[j]])
}
D = append(D, DpopJ)
}
D = lapply(D, scale)
### now run various models & store results:
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
lamMOG
lamMOG= regChoice(D=D, lambda = c(0.05, .1, .15, .2), K=2, SampleNo = 10, Ptype="Classic")
lamMOG
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
X$iter
round(X$Z)
X$iter
round(X$Z)
lamMOG=.05
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
X$iter
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
X$iter
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
X$iter
round(X$Z)
lamMOG=.1
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.00001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.001)
round(X$Z)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.001)
round(X$Z)
lamMOG
subNum
trueClust = c(rep(1,subNum), rep(2, subNum))
trueEdges = c()
reportedEdges = c()
for (k in 1:(2*subNum)){
# get estimated cluster for kth subject:
P_Est_k = X$Theta[,, which.max(X$Z[k,])]
#     getPerformance(Est = P_Est_k, True = P[[trueClust[k]]])
trueEdges = c(trueEdges, 1*(P[[trueClust[k]]][upper.tri(P_Est_k)]!=0))
reportedEdges = c(reportedEdges, 1*(P_Est_k[upper.tri(P_Est_k)]!=0))
}
res = HMeasure(true.class = trueEdges, scores = reportedEdges )
plot(res)
summary(res)
res$metrics$TP
res$metrics$FP
res$metrics$TPR
res$metrics$FPR
res$metrics$TRP
res$metrics
sum(P[[1]][upper.tri(P[[1]])]!=0)
dim(P[[1]])
choose(20,2)
set.seed(i)
randomNetworks = Gen2SharedNetworks(p = p, rho = rho, sparsity = .2)
P = vector("list", 2)
P[[1]] = randomNetworks$y
P[[2]] = randomNetworks$y2
### now simulate data:
D = NULL
for (j in 1:popNum){
DpopJ = vector("list", subNum)
for (k in 1:subNum){
DpopJ[[k]] = mvrnorm(n = n, mu = rep(0, p), P[[j]])
}
D = append(D, DpopJ)
}
D = lapply(D, scale)
### now run various models & store results:
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.001)
round(X$Z)
trueClust = c(rep(1,subNum), rep(2, subNum))
trueEdges = c()
reportedEdges = c()
for (k in 1:(2*subNum)){
# get estimated cluster for kth subject:
P_Est_k = X$Theta[,, which.max(X$Z[k,])]
#     getPerformance(Est = P_Est_k, True = P[[trueClust[k]]])
trueEdges = c(trueEdges, 1*(P[[trueClust[k]]][upper.tri(P_Est_k)]!=0))
reportedEdges = c(reportedEdges, 1*(P_Est_k[upper.tri(P_Est_k)]!=0))
}
res = HMeasure(true.class = trueEdges, scores = reportedEdges )
ResultsMoG$SimID[i] = i
ResultsMoG$TP[i] = res$metrics$TP
ResultsMoG$FP[i] = res$metrics$FP
ResultsMoG$Sens[i] = res$metrics$TPR
ResultsMoG$Spec[i] = res$metrics$TN/(res$metrics$FP + res$metrics$TN)
ResultsMoG$FDR[i] = res$metrics$FPR
ResultsMoG$TPR[i] = res$metrics$TPR
res$metrics$TP
res$metrics$FP
res$metrics$TPR
res$metrics$FPR
res$metrics$Sens
lamMOG
lamMOG = .2
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.001)
round(X$Z)
trueClust = c(rep(1,subNum), rep(2, subNum))
trueEdges = c()
reportedEdges = c()
for (k in 1:(2*subNum)){
# get estimated cluster for kth subject:
P_Est_k = X$Theta[,, which.max(X$Z[k,])]
#     getPerformance(Est = P_Est_k, True = P[[trueClust[k]]])
trueEdges = c(trueEdges, 1*(P[[trueClust[k]]][upper.tri(P_Est_k)]!=0))
reportedEdges = c(reportedEdges, 1*(P_Est_k[upper.tri(P_Est_k)]!=0))
}
res$metrics$Sens
res$metrics$FPR
ii = which(P[[1]][upper.tri(P[[1]])]!=0)
length(ii)
iiT = which(X$Theta[,,1][upper.tri(P[[1]])]!=0)
length(iiT)
X$Theta[,,1][upper.tri(P[[1]])]
lamMOG
dim(X$Theta)
X$Theta[,,2][upper.tri(P[[1]])]
lamMOG
lamMOG=0.05
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.001)
round(X$Z)
X$iter
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.001)
round(X$Z)
trueClust = c(rep(1,subNum), rep(2, subNum))
trueEdges = c()
reportedEdges = c()
for (k in 1:(2*subNum)){
# get estimated cluster for kth subject:
P_Est_k = X$Theta[,, which.max(X$Z[k,])]
#     getPerformance(Est = P_Est_k, True = P[[trueClust[k]]])
trueEdges = c(trueEdges, 1*(P[[trueClust[k]]][upper.tri(P_Est_k)]!=0))
reportedEdges = c(reportedEdges, 1*(P_Est_k[upper.tri(P_Est_k)]!=0))
}
res$metrics$Sens
res$metrics$FPR
X$Theta[,,2][upper.tri(P[[1]])]
X$Theta[,,1][upper.tri(P[[1]])]
res = HMeasure(true.class = trueEdges, scores = reportedEdges )
res$metrics$Sens
res$metrics$FPR
lamMOG
lamMOG=.1
lamMOG=.075
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.001)
round(X$Z)
trueClust = c(rep(1,subNum), rep(2, subNum))
trueEdges = c()
reportedEdges = c()
for (k in 1:(2*subNum)){
# get estimated cluster for kth subject:
P_Est_k = X$Theta[,, which.max(X$Z[k,])]
#     getPerformance(Est = P_Est_k, True = P[[trueClust[k]]])
trueEdges = c(trueEdges, 1*(P[[trueClust[k]]][upper.tri(P_Est_k)]!=0))
reportedEdges = c(reportedEdges, 1*(P_Est_k[upper.tri(P_Est_k)]!=0))
}
res = HMeasure(true.class = trueEdges, scores = reportedEdges )
res$metrics$Sens
res$metrics$FPR
rho
rho = .1
set.seed(i)
randomNetworks = Gen2SharedNetworks(p = p, rho = rho, sparsity = .2)
P = vector("list", 2)
P[[1]] = randomNetworks$y
P[[2]] = randomNetworks$y2
### now simulate data:
D = NULL
for (j in 1:popNum){
DpopJ = vector("list", subNum)
for (k in 1:subNum){
DpopJ[[k]] = mvrnorm(n = n, mu = rep(0, p), P[[j]])
}
D = append(D, DpopJ)
}
D = lapply(D, scale)
lamMOG
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.001)
round(X$Z)
trueClust = c(rep(1,subNum), rep(2, subNum))
trueEdges = c()
reportedEdges = c()
for (k in 1:(2*subNum)){
# get estimated cluster for kth subject:
P_Est_k = X$Theta[,, which.max(X$Z[k,])]
#     getPerformance(Est = P_Est_k, True = P[[trueClust[k]]])
trueEdges = c(trueEdges, 1*(P[[trueClust[k]]][upper.tri(P_Est_k)]!=0))
reportedEdges = c(reportedEdges, 1*(P_Est_k[upper.tri(P_Est_k)]!=0))
}
res = HMeasure(true.class = trueEdges, scores = reportedEdges )
res$metrics$Sens
res$metrics$FPR
i=2
set.seed(i)
randomNetworks = Gen2SharedNetworks(p = p, rho = rho, sparsity = .2)
P = vector("list", 2)
P[[1]] = randomNetworks$y
P[[2]] = randomNetworks$y2
### now simulate data:
D = NULL
for (j in 1:popNum){
DpopJ = vector("list", subNum)
for (k in 1:subNum){
DpopJ[[k]] = mvrnorm(n = n, mu = rep(0, p), P[[j]])
}
D = append(D, DpopJ)
}
D = lapply(D, scale)
### now run various models & store results:
lamMOG = .075
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.001)
round(X$Z)
regChoiceJGL
FGL
?JGL
lamFGL = regChoiceJGL(D = D_FLG, l1=c(.05, .1, .2), l2 = c(.2, .3))
D_FLG = array(0, c(n,p,2*subNum))
for (k in 1:(2*subNum)){
D_FLG[,,k] = D[[k]]
}
lamFGL = regChoiceJGL(D = D_FLG, l1=c(.05, .1, .2), l2 = c(.2, .3))
lamFGL
X = JGL(Y = D, penalty = "group", lambda1 = lamFGL$l1, lambda2 = lamFGL$l2 )
trueEdges = c()
reportedEdges = c()
for (k in 1:(2*subNum)){
# get estimated cluster for kth subject:
P_Est_k = X$Z[,,k]
trueEdges = c(trueEdges, 1*(P[[trueClust[k]]][upper.tri(P_Est_k)]!=0))
reportedEdges = c(reportedEdges, 1*(P_Est_k[upper.tri(P_Est_k)]!=0))
}
names(X)
dim(X$theta)
length(X$theta)
trueEdges = c()
reportedEdges = c()
for (k in 1:(2*subNum)){
# get estimated cluster for kth subject:
P_Est_k = X$theta[[k]]
trueEdges = c(trueEdges, 1*(P[[trueClust[k]]][upper.tri(P_Est_k)]!=0))
reportedEdges = c(reportedEdges, 1*(P_Est_k[upper.tri(P_Est_k)]!=0))
}
res = HMeasure(true.class = trueEdges, scores = reportedEdges )
res$metrics$FPR
res$metrics$Sens
summary(res)
X = PenVanillaEM(D = D, K = 2, lambda = lamMOG, Ptype = "Classic", tol = 0.001)
round(X$Z)
trueClust = c(rep(1,subNum), rep(2, subNum))
trueEdges = c()
reportedEdges = c()
for (k in 1:(2*subNum)){
# get estimated cluster for kth subject:
P_Est_k = X$Theta[,, which.max(X$Z[k,])]
#     getPerformance(Est = P_Est_k, True = P[[trueClust[k]]])
trueEdges = c(trueEdges, 1*(P[[trueClust[k]]][upper.tri(P_Est_k)]!=0))
reportedEdges = c(reportedEdges, 1*(P_Est_k[upper.tri(P_Est_k)]!=0))
}
res = HMeasure(true.class = trueEdges, scores = reportedEdges )
summary(res)
trueEdges = c()
reportedEdges = c()
for (k in 1:(2*subNum)){
# choose reg parameter first:
lamGlassoK = regChoiceGlasso(D[[k]], l1=c(.05, .1, .2))
# get estimated cluster for kth subject:
P_Est_k = glasso(cov(D[[k]]), rho=lamGlassoK)$wi
trueEdges = c(trueEdges, 1*(P[[trueClust[k]]][upper.tri(P_Est_k)]!=0))
reportedEdges = c(reportedEdges, 1*(P_Est_k[upper.tri(P_Est_k)]!=0))
}
res = HMeasure(true.class = trueEdges, scores = reportedEdges )
summary(res0
)
summary(res)
res$metrics$AUC
ResultsMoG = data.frame(matrix(0, ncol=10, nrow=Nsims))
names(ResultsMoG) = c("SimID", "TP", "FP", "Sens", "Spec", "FDR", "TPR", "Pres", "Recall", "AUC")
ResultsFGL= data.frame(matrix(0, ncol=10, nrow=Nsims))
names(ResultsFGL) = c("SimID", "TP", "FP", "Sens", "Spec", "FDR", "TPR", "Pres", "Recall", "AUC")
ResultsGGL= data.frame(matrix(0, ncol=10, nrow=Nsims))
names(ResultsGGL) = c("SimID", "TP", "FP", "Sens", "Spec", "FDR", "TPR", "Pres", "Recall", "AUC")
ResultsGL= data.frame(matrix(0, ncol=10, nrow=Nsims))
ResultsGL= data.frame(matrix(0, ncol=10, nrow=Nsims))
names(ResultsGL) = c("SimID", "TP", "FP", "Sens", "Spec", "FDR", "TPR", "Pres", "Recall", "AUCS")
names(ResultsGL) = c("SimID", "TP", "FP", "Sens", "Spec", "FDR", "TPR", "Pres", "Recall", "AUC")
rm(list=ls())
gc()
rm(list=ls())
gc()
setwd('/media/1401-1FFE/Documents/Dynamic Covariance Estimation/Kernel Smoothing/Real_Data_Analysis/Patients2/')
library(R.matlab)
data = readMat('ForRicardo.mat')
dim(data)
length(data)
data = data$big.mc.clean.matrix
dim(data)
pat_no=12
sdata = data[,,1][pat_no,]
for (i in 2:126){
sdata = rbind(sdata, data[,,i][pat_no,])
}
dim(sdata)
plot(sdata[,1])
plot(sdata[,1], type='l')
# save this:
getwd()
setwd('//media/1401-1FFE/Documents/RETNE/Code/Sample Data/')
getwd()
?write.csv
sdata = scale(sdata)
write.csv(sdata, file='SampleSubject.csv', row.names=FALSE)
